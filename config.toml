# config.toml (v2.0 - Top-Tier Free Council)

# The Rapporteur MUST be the most powerful model. Llama 3.1 405B is, by a huge margin,
# the largest and most capable free model available. It is the only choice for this role.
[rapporteur]
model = "meta-llama/llama-3.1-405b"

# This council is designed for maximum power and diversity from the best available free models.
[models]
"Llama 3.1 405B (Heavyweight)" = "meta-llama/llama-3.1-405b"
"Mistral Nemo (Main Rival)" = "mistralai/mistral-nemo"
"Phi-4 Reasoning Plus (Specialist)" = "microsoft/phi-4-reasoning-plus"
"Llama 3.3 70B (Senior Advisor)" = "meta-llama/llama-3.3-70b-instruct"

# Prompt templates remain unchanged. They are model-agnostic.
[prompt_templates]
tech_stack = "Given these requirements: {requirements}, what technology stack would you recommend? Analyze trade-offs in terms of cost, scalability, and developer experience."
scaling_strategy = "For a system described as '{system_description}', propose a robust scaling strategy. Cover database, application layer, and potential caching solutions."
code_review = "Please act as a senior software engineer and provide a thorough code review for the following snippet. Focus on correctness, clarity, and potential performance issues. Here is the code: {code_snippet}"
risk_assessment = "Analyze potential risks and failure modes for this architecture: {architecture_description}. Include technical, operational, and business risks."
team_fit = "Given a team of {team_size} developers with {experience_level} experience, evaluate whether this approach is suitable: {proposed_approach}"